{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f473e61-2f35-4852-9ea4-dac28cf991fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import bisect\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder, MultiLabelBinarizer\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "242b0940-9e0d-4f45-aa00-6a0e193ed4d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class InductiveConformalPredictor():\n",
    "    def __init__(self, predictor):\n",
    "        self.predictor = predictor\n",
    "        \n",
    "        self._le = LabelEncoder()\n",
    "        self.classes = self._le.fit_transform(predictor.classes_)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.calibration_score = self._uncertainty_conformity_score(X)\n",
    "        self.calibration_class = self._le.transform(y)\n",
    "        return self\n",
    "\n",
    "    def _uncertainty_conformity_score(self, data):\n",
    "        uncertainty_score = 1 - self.predictor.predict_proba(data)\n",
    "        return uncertainty_score\n",
    "\n",
    "    def predict_proba(self, X, mondrian=True):\n",
    "        conformity_score = self._uncertainty_conformity_score(X)\n",
    "        conformal_pred = np.zeros(conformity_score.shape)\n",
    "\n",
    "        for c in self.classes:\n",
    "            if mondrian:\n",
    "                calibration_filt = self.calibration_score[\n",
    "                    self.calibration_class == c\n",
    "                ]\n",
    "                calib = calibration_filt[:, c]\n",
    "            else:\n",
    "                calib = self.calibration_score[\n",
    "                    range(len(self.calibration_class)), \n",
    "                    self.calibration_class\n",
    "                ]\n",
    "\n",
    "            sorted_calib = np.sort(calib)\n",
    "            conformal_pred[:, c] = [\n",
    "                float(bisect.bisect(sorted_calib, x))/len(calib)\n",
    "                for x in conformity_score[:, c]\n",
    "            ]\n",
    "\n",
    "        return conformal_pred\n",
    "\n",
    "    def predict(self, X, mondrian=True, alpha=0.05):\n",
    "        _conformal_proba = self.predict_proba(X=X, mondrian=mondrian)\n",
    "        conformal_pred = (_conformal_proba > alpha).astype(int)\n",
    "\n",
    "        mlb = MultiLabelBinarizer()\n",
    "        mlb.fit([self._le.classes_])\n",
    "        pred = mlb.inverse_transform(conformal_pred)\n",
    "\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fae0a487-f2c7-489d-8d0a-17ff6f89e035",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ConformalInferenceExperiment:\n",
    "    def __init__(self, data, target, n_splits=5, coverage_quantiles=[0.25, 0.5, 0.75], random_state=42):\n",
    "        self.data = data\n",
    "        self.target = target\n",
    "        self.n_splits = n_splits\n",
    "        self.coverage_quantiles = coverage_quantiles\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def get_coverage(self, cfp, X_test, alpha_interval):\n",
    "        coverage = np.array([\n",
    "            np.array([len(y_set) == 1\n",
    "                      for y_set in cfp.predict(X_test, alpha=alpha)]).mean()\n",
    "            for alpha in alpha_interval\n",
    "        ])\n",
    "        return coverage\n",
    "\n",
    "    def run(self):\n",
    "        y = self.data[self.target]\n",
    "        X = self.data.drop(self.target, axis=1)\n",
    "\n",
    "        kf = KFold(n_splits=self.n_splits, shuffle=True, random_state=self.random_state)\n",
    "        model = LogisticRegression(max_iter=1000, random_state=self.random_state)\n",
    "\n",
    "        metrics = {\n",
    "            'overall_accuracy': [],\n",
    "            'overall_f1_score': []\n",
    "        }\n",
    "        for q in self.coverage_quantiles:\n",
    "            metrics[f\"top_{int(q * 100)}_accuracy\"] = []\n",
    "            metrics[f\"top_{int(q * 100)}_f1_score\"] = []\n",
    "\n",
    "        for train_index, test_index in kf.split(X):\n",
    "            X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "            X_train, X_calib, y_train, y_calib = train_test_split(\n",
    "                X_train, y_train, test_size=0.3,\n",
    "                stratify=y_train, random_state=self.random_state\n",
    "            )\n",
    "\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_test)\n",
    "            \n",
    "            cfp = InductiveConformalPredictor(predictor=model)\n",
    "            cfp.fit(X_calib, y_calib)\n",
    "\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            metrics[\"overall_accuracy\"].append(accuracy)\n",
    "\n",
    "            f1 = f1_score(y_test, y_pred)\n",
    "            metrics[\"overall_f1_score\"].append(f1)\n",
    "\n",
    "            alpha_interval = np.arange(0, .9, .01)\n",
    "            coverage = self.get_coverage(cfp, X_test, alpha_interval)\n",
    "\n",
    "            for q in self.coverage_quantiles:\n",
    "                index = np.argmin(np.abs(coverage - q))\n",
    "\n",
    "                y_test_sets = cfp.predict(X_test, alpha=alpha_interval[index])\n",
    "                indexes = np.where(np.vectorize(len)(y_test_sets) == 1)\n",
    "\n",
    "                accuracy = accuracy_score(y_test.values[indexes], y_pred[indexes])\n",
    "                metrics[f\"top_{int(q * 100)}_accuracy\"].append(accuracy)\n",
    "\n",
    "                f1 = f1_score(y_test.values[indexes], y_pred[indexes])\n",
    "                metrics[f\"top_{int(q * 100)}_f1_score\"].append(f1)\n",
    "\n",
    "        return pd.DataFrame(metrics).describe().T[[\"mean\", \"std\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e11a776-b734-4cc9-b940-6945d71b83c8",
   "metadata": {},
   "source": [
    "## Heart Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e92bbc07-36a7-4b6a-a616-57ec484fe9ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.17 s, sys: 5.68 ms, total: 1.18 s\n",
      "Wall time: 1.18 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>overall_accuracy</th>\n",
       "      <td>0.841987</td>\n",
       "      <td>0.045861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>overall_f1_score</th>\n",
       "      <td>0.854634</td>\n",
       "      <td>0.046175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top_25_accuracy</th>\n",
       "      <td>0.943466</td>\n",
       "      <td>0.024380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top_25_f1_score</th>\n",
       "      <td>0.952350</td>\n",
       "      <td>0.018114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top_50_accuracy</th>\n",
       "      <td>0.917440</td>\n",
       "      <td>0.028990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top_50_f1_score</th>\n",
       "      <td>0.929177</td>\n",
       "      <td>0.024686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top_75_accuracy</th>\n",
       "      <td>0.901095</td>\n",
       "      <td>0.034858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top_75_f1_score</th>\n",
       "      <td>0.909748</td>\n",
       "      <td>0.033008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      mean       std\n",
       "overall_accuracy  0.841987  0.045861\n",
       "overall_f1_score  0.854634  0.046175\n",
       "top_25_accuracy   0.943466  0.024380\n",
       "top_25_f1_score   0.952350  0.018114\n",
       "top_50_accuracy   0.917440  0.028990\n",
       "top_50_f1_score   0.929177  0.024686\n",
       "top_75_accuracy   0.901095  0.034858\n",
       "top_75_f1_score   0.909748  0.033008"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "heart = pd.read_csv(\"../data/processed/heart.csv\")\n",
    "\n",
    "experiment = ConformalInferenceExperiment(\n",
    "    data=heart, \n",
    "    target=\"HeartDisease\",\n",
    "    random_state=RANDOM_SEED\n",
    ")\n",
    "metrics = experiment.run()\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f2d135-e2b8-4aad-980b-13d92cffe52c",
   "metadata": {},
   "source": [
    "## Australian Credit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "85e1417d-ea57-4835-ba68-9f633ac32037",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.39 s, sys: 6.16 ms, total: 1.4 s\n",
      "Wall time: 1.4 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>overall_accuracy</th>\n",
       "      <td>0.856522</td>\n",
       "      <td>0.028712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>overall_f1_score</th>\n",
       "      <td>0.835903</td>\n",
       "      <td>0.037906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top_25_accuracy</th>\n",
       "      <td>0.942017</td>\n",
       "      <td>0.054252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top_25_f1_score</th>\n",
       "      <td>0.922652</td>\n",
       "      <td>0.088812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top_50_accuracy</th>\n",
       "      <td>0.939122</td>\n",
       "      <td>0.034875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top_50_f1_score</th>\n",
       "      <td>0.930957</td>\n",
       "      <td>0.040429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top_75_accuracy</th>\n",
       "      <td>0.918155</td>\n",
       "      <td>0.022458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top_75_f1_score</th>\n",
       "      <td>0.909308</td>\n",
       "      <td>0.018027</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      mean       std\n",
       "overall_accuracy  0.856522  0.028712\n",
       "overall_f1_score  0.835903  0.037906\n",
       "top_25_accuracy   0.942017  0.054252\n",
       "top_25_f1_score   0.922652  0.088812\n",
       "top_50_accuracy   0.939122  0.034875\n",
       "top_50_f1_score   0.930957  0.040429\n",
       "top_75_accuracy   0.918155  0.022458\n",
       "top_75_f1_score   0.909308  0.018027"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "australian = pd.read_csv(\"../data/processed/australian.csv\")\n",
    "\n",
    "experiment = ConformalInferenceExperiment(\n",
    "    data=australian, \n",
    "    target=\"14\",\n",
    "    random_state=RANDOM_SEED\n",
    ")\n",
    "metrics = experiment.run()\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065fa08f-9e2e-4112-9010-ec8c2d1c569b",
   "metadata": {},
   "source": [
    "## Diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6fb9c567-09b2-4253-afdd-f884cf0ae1b6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 842 ms, sys: 3.7 ms, total: 846 ms\n",
      "Wall time: 846 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>overall_accuracy</th>\n",
       "      <td>0.768237</td>\n",
       "      <td>0.024967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>overall_f1_score</th>\n",
       "      <td>0.630647</td>\n",
       "      <td>0.032666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top_25_accuracy</th>\n",
       "      <td>0.892794</td>\n",
       "      <td>0.021332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top_25_f1_score</th>\n",
       "      <td>0.856557</td>\n",
       "      <td>0.060112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top_50_accuracy</th>\n",
       "      <td>0.867799</td>\n",
       "      <td>0.036305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top_50_f1_score</th>\n",
       "      <td>0.832877</td>\n",
       "      <td>0.040517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top_75_accuracy</th>\n",
       "      <td>0.797269</td>\n",
       "      <td>0.029223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top_75_f1_score</th>\n",
       "      <td>0.723040</td>\n",
       "      <td>0.029513</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      mean       std\n",
       "overall_accuracy  0.768237  0.024967\n",
       "overall_f1_score  0.630647  0.032666\n",
       "top_25_accuracy   0.892794  0.021332\n",
       "top_25_f1_score   0.856557  0.060112\n",
       "top_50_accuracy   0.867799  0.036305\n",
       "top_50_f1_score   0.832877  0.040517\n",
       "top_75_accuracy   0.797269  0.029223\n",
       "top_75_f1_score   0.723040  0.029513"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "diabetes = pd.read_csv(\"../data/processed/diabetes.csv\")\n",
    "\n",
    "experiment = ConformalInferenceExperiment(\n",
    "    data=diabetes, \n",
    "    target=\"Outcome\",\n",
    "    random_state=RANDOM_SEED\n",
    ")\n",
    "metrics = experiment.run()\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661e8025-71fb-44a8-b404-3cbcf0923b4c",
   "metadata": {},
   "source": [
    "## Qsar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "70f7b668-01bf-4fce-adab-08a17c19f8a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.45 s, sys: 837 ms, total: 6.29 s\n",
      "Wall time: 1.38 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>overall_accuracy</th>\n",
       "      <td>0.854028</td>\n",
       "      <td>0.022077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>overall_f1_score</th>\n",
       "      <td>0.780188</td>\n",
       "      <td>0.046006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top_25_accuracy</th>\n",
       "      <td>0.977493</td>\n",
       "      <td>0.030388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top_25_f1_score</th>\n",
       "      <td>0.957110</td>\n",
       "      <td>0.063850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top_50_accuracy</th>\n",
       "      <td>0.950507</td>\n",
       "      <td>0.016588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top_50_f1_score</th>\n",
       "      <td>0.926547</td>\n",
       "      <td>0.036069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top_75_accuracy</th>\n",
       "      <td>0.902687</td>\n",
       "      <td>0.016916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top_75_f1_score</th>\n",
       "      <td>0.862471</td>\n",
       "      <td>0.025067</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      mean       std\n",
       "overall_accuracy  0.854028  0.022077\n",
       "overall_f1_score  0.780188  0.046006\n",
       "top_25_accuracy   0.977493  0.030388\n",
       "top_25_f1_score   0.957110  0.063850\n",
       "top_50_accuracy   0.950507  0.016588\n",
       "top_50_f1_score   0.926547  0.036069\n",
       "top_75_accuracy   0.902687  0.016916\n",
       "top_75_f1_score   0.862471  0.025067"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "qsar = pd.read_csv(\"../data/processed/qsar.csv\")\n",
    "\n",
    "experiment = ConformalInferenceExperiment(\n",
    "    data=qsar, \n",
    "    target=\"Class\",\n",
    "    random_state=RANDOM_SEED\n",
    ")\n",
    "metrics = experiment.run()\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2abb0c1d-f8f9-4f52-8d71-e530a7b5b065",
   "metadata": {},
   "source": [
    "## Titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f4eaf3f2-2654-42af-b60b-0b0d59960547",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.27 s, sys: 3.71 ms, total: 1.27 s\n",
      "Wall time: 1.27 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>overall_accuracy</th>\n",
       "      <td>0.794595</td>\n",
       "      <td>0.029221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>overall_f1_score</th>\n",
       "      <td>0.721170</td>\n",
       "      <td>0.052346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top_25_accuracy</th>\n",
       "      <td>0.922130</td>\n",
       "      <td>0.054371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top_25_f1_score</th>\n",
       "      <td>0.900926</td>\n",
       "      <td>0.077954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top_50_accuracy</th>\n",
       "      <td>0.890366</td>\n",
       "      <td>0.024365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top_50_f1_score</th>\n",
       "      <td>0.863451</td>\n",
       "      <td>0.045495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top_75_accuracy</th>\n",
       "      <td>0.845207</td>\n",
       "      <td>0.023340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top_75_f1_score</th>\n",
       "      <td>0.810099</td>\n",
       "      <td>0.044441</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      mean       std\n",
       "overall_accuracy  0.794595  0.029221\n",
       "overall_f1_score  0.721170  0.052346\n",
       "top_25_accuracy   0.922130  0.054371\n",
       "top_25_f1_score   0.900926  0.077954\n",
       "top_50_accuracy   0.890366  0.024365\n",
       "top_50_f1_score   0.863451  0.045495\n",
       "top_75_accuracy   0.845207  0.023340\n",
       "top_75_f1_score   0.810099  0.044441"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "titanic = pd.read_csv(\"../data/processed/titanic.csv\")\n",
    "\n",
    "experiment = ConformalInferenceExperiment(\n",
    "    data=titanic, \n",
    "    target=\"Survived\",\n",
    "    random_state=RANDOM_SEED\n",
    ")\n",
    "metrics = experiment.run()\n",
    "metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
